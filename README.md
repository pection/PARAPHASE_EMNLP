# SPLINT

This code is associated with the **SPLINT: SParse Learning for INterpretable Tuning** paper.  
Our work extends the research presented in [**SparseFit: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations**](https://arxiv.org/abs/2305.13235). We have used their codebase as a foundation for this project and improved it for usability, reproducibility, and ease of experimentation.

---

SPLINT is a **refactored and extended version** of a larger framework for training and evaluating T5-based models (like UnifiedQA) across various explanation and reasoning tasks using multiple random seeds.

> **Why this version?**  
> This is a **lightweight, single-GPU version** of SPLINT designed for testing and demonstration. It already includes improvements like **custom loss functions** and a cleaner training workflow.  

> ğŸ”“ The **full version**, will be released upon paper acceptance, supports **multi-GPU training**, **flexible experiment configuration**, and **scalable runs across datasets and models**.

---

## ğŸ“¦ Installation

### 1. Create and activate a virtual environment

```bash
python3.10 -m venv SPLINT
source SPLINT/bin/activate
```

### 2. Install the dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸ Run Training

### Quick Start

To start training and evaluating with default settings:

```bash
python scripts/traning.py
```

This will:
- Train selected models on supported datasets
- Automatically apply optimal IO formats
- Run experiments using 60 random seeds

---
## ğŸ“ˆ Collect Results

After completing all 60 seed runs:

```bash
mkdir out
python scripts/benchmark_result.py \
  --exp_root checkpoints \
  --output out
```

This will generate a report of **mean** and **standard deviation** for all experimental setups.

> ğŸ’¡ If you get an `AssertionError`, some seed runs likely failed. Identify the missing runs, re-run them, and rerun the results collection script.

---

## ğŸ“ Directory Structure

```
..
â”œâ”€â”€ data/              # External folder containing raw data files
â””â”€â”€ SPLINT/
    â”œâ”€â”€ data/           # Inside folder containing raw data files
    â”œâ”€â”€ checkpoints/           
    â”œâ”€â”€ scripts/               # All training and utility scripts
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ benchmark_result.py
    â”‚   â”œâ”€â”€ compute_kappa.py
    â”‚   â”œâ”€â”€ custom_args.py
    â”‚   â”œâ”€â”€ custom_loss_class.py
    â”‚   â”œâ”€â”€ exp.py
    â”‚   â”œâ”€â”€ feature_conversion_methods.py
    â”‚   â”œâ”€â”€ metrics_custom_loss.py
    â”‚   â”œâ”€â”€ preprocess_data.py
    â”‚   â”œâ”€â”€ samples_for_human_eval.py
    â”‚   â”œâ”€â”€ training.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â””â”€â”€ .gitignore
```